<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CNN,深度学习,卷积神经网络,DeepLearning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="卷积神经网络概述20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks,CNN）。现在，卷积神经网络是深度学习技术中极具代表的网络结构之一，在模式分类领域，特别是在图像处理领域取得了很大的成功，在国际标准ImageNet数据">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习笔记：卷积神经网络（CNN）基础概念梳理">
<meta property="og:url" content="http://yoursite.com/2017/03/19/深度学习-卷积神经网络基础/index.html">
<meta property="og:site_name" content="WONDER'TWO">
<meta property="og:description" content="卷积神经网络概述20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks,CNN）。现在，卷积神经网络是深度学习技术中极具代表的网络结构之一，在模式分类领域，特别是在图像处理领域取得了很大的成功，在国际标准ImageNet数据">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/cnn_article_cover_2.jpg">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E9%A2%9D%E6%98%82%E7%BD%97%E6%A6%82%E5%BF%B5%E5%9B%BE.png">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/CNN%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5%E4%B8%8E%E6%9D%83%E5%80%BC%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB.gif">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/CNN%E6%B1%A0%E5%8C%96%E8%BF%87%E7%A8%8B%E6%9C%80%E5%A4%A7%E5%80%BC%E9%87%87%E6%A0%B7%E7%A4%BA%E6%84%8F%E5%9B%BE.png">
<meta property="og:image" content="http://on1xkrize.bkt.clouddn.com/CNN%E7%BB%8F%E5%85%B8Lenet-5%E7%BB%93%E6%9E%84%E5%9B%BE.png">
<meta property="og:updated_time" content="2017-03-19T13:39:22.689Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="深度学习笔记：卷积神经网络（CNN）基础概念梳理">
<meta name="twitter:description" content="卷积神经网络概述20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks,CNN）。现在，卷积神经网络是深度学习技术中极具代表的网络结构之一，在模式分类领域，特别是在图像处理领域取得了很大的成功，在国际标准ImageNet数据">
<meta name="twitter:image" content="http://on1xkrize.bkt.clouddn.com/cnn_article_cover_2.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'WonderTwo[@布鲁克林一棵树]'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/03/19/深度学习-卷积神经网络基础/"/>





  <title> 深度学习笔记：卷积神经网络（CNN）基础概念梳理 | WONDER'TWO </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0af291142256bedaa2172682f765d1c7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WONDER'TWO</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">好看的皮囊千篇一律，有趣的人格万里挑一！</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            博客首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            博客归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            文章标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            博客分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于博主
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
  <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/03/19/深度学习-卷积神经网络基础/">

  <span style="display:none" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="name" content="布鲁克林一棵树">
    <meta itemprop="description" content="">
    <meta itemprop="image" content="/images/avatar.gif">
  </span>

  <span style="display:none" itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="WONDER'TWO">
    <span style="display:none" itemprop="logo" itemscope itemtype="http://schema.org/ImageObject">
      <img style="display:none;" itemprop="url image" alt="WONDER'TWO" src="">
    </span>
  </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                深度学习笔记：卷积神经网络（CNN）基础概念梳理
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-03-19T11:11:11+08:00">
                2017-03-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机基础知识/" itemprop="url" rel="index">
                    <span itemprop="name">计算机基础知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算机基础知识/深度学习网络/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习网络</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p><img src="http://on1xkrize.bkt.clouddn.com/cnn_article_cover_2.jpg" alt=""></p>
<h3 id="卷积神经网络概述"><a href="#卷积神经网络概述" class="headerlink" title="卷积神经网络概述"></a>卷积神经网络概述</h3><p>20世纪60年代，Hubel和Wiesel在研究猫脑皮层中用于局部敏感和方向选择的神经元时发现其独特的网络结构可以有效地降低反馈神经网络的复杂性，继而提出了卷积神经网络（Convolutional Neural Networks,CNN）。现在，卷积神经网络是深度学习技术中极具代表的网络结构之一，在模式分类领域，特别是在图像处理领域取得了很大的成功，在国际标准ImageNet数据集上，许多成功的模型都是基于CNN的。CNN相较于传统的图像处理算法的优点之一在于，避免了对图像复杂的前期预处理过程（提取人工特征等），可以直接输入原始图像。卷积神经网络以其局部连接和权值共享两大特性，在语音识别和图像处理方面有着独特的优越性。主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。CNN概念图如下：</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E9%A2%9D%E6%98%82%E7%BD%97%E6%A6%82%E5%BF%B5%E5%9B%BE.png" alt=""></p>
<p>一般地，CNN的基本结构包括四层模型，可有如下表达式来概括：</p>
<pre><code>Input -&gt; [m * Conv + ? * Pool] * n -&gt; FC -&gt; Output
</code></pre><a id="more"></a>
<p>以上表达式中，Input表示输入层，Output表示输出层，都很好理解，关键在于中间两层。</p>
<ul>
<li><code>[m * Conv + ? * Pool] * n</code> 表示卷积池化层。里面涉及到两个非常非常非常重要的概念：卷积和池化，下文会详细介绍。卷积池化层的主要作用是，在输入数据集上，通过m层的卷积操作，以及0层或者多层的池化操作，提取输入数据集的高维特征，最后提到的高维特征图集合，整体作为下一层的输入。</li>
<li><code>FC</code> 表示全连接网络层。本质上来讲，全连接层模型和我们已经了解的普通的多层深度神经网络相似，不同点在于每个CNN的全连接层在选用激活函数和调整权值参数（BP, 反向传播算法）的算法会更加复杂。我们已经知道，普通深层神经网络的作用是，对输入数据集进行分类。同样的，全连接层的作用是，对卷积池化层得到的输入数据集的高维特征图集合进行分类处理。</li>
</ul>
<p>卷积神经网络的核心思想是：局部感受野(local field)，权值共享以及时间或空间下采样这三种思想结合起来，获得了某种程度的位移、尺度、形变不变性（⊙o⊙…其实。对这句话我也不是很理解~~~）。</p>
<h3 id="局部连接与权值共享"><a href="#局部连接与权值共享" class="headerlink" title="局部连接与权值共享"></a>局部连接与权值共享</h3><p>局部连接与权值共享是卷积神将网络得以在多个领域大放异彩的理论基础。先来看局部连接，局部连接是与全连接相对而言的。为了更加直观的理解二者的区别，请看下图：</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5%E4%B8%8E%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt=""></p>
<p>左半图表示全连接，显示了一个神经元（节点）与另一层的n个神经节点（我们可以图片看成由n个神经元节点排列组合而成）全部的所有的连接。与我们之前了解的普通多层神经网络相似，全连接网络中，每一层中的每一个神经节点都会与下一层的所有神经节点进行连接。相反的，右半图表示局部连接，一个节点只与另一层局部区域内的每个节点连接。</p>
<p>采用局部连接的一个好处是：极大地减少了神经网络需要训练的权值参数的个数。在上图中，我们假设一个1000 × 1000的输入图像而言，如果下一个隐藏层的神经元数目为10^6个，采用全连接则有1000 × 1000 × 10^6 = 10^12个权值参数，如此数目巨大的参数几乎难以训练；而采用局部连接，隐藏层的每个神经元仅与图像中10 × 10的局部图像相连接，那么此时的权值参数数量为10 × 10 × 10^6 = 10^8，将直接减少4个数量级。</p>
<p>尽管减少了几个数量级，但参数数量依然较多。能不能再进一步减少呢？能！方法就是权值共享。具体做法是，在局部连接中隐藏层的每一个神经元连接的是一个10 × 10的局部图像，因此有10 × 10个权值参数，将这10 × 10个权值参数共享给剩下的神经元，也就是说隐藏层中10^6个神经元的权值参数相同，那么此时不管隐藏层神经元的数目是多少，需要训练的参数就是这 10 × 10个权值参数（也就是卷积核(也称滤波器)的大小），如下图：</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9D%83%E5%80%BC%E5%85%B1%E4%BA%AB%E7%A4%BA%E6%84%8F%E5%9B%BE.jpg" alt=""></p>
<p>CNN的一个神奇之处就是，尽管只有这么少的参数，依旧有出色的性能。但是，这样仅提取了图像的一种特征，如果要多提取出一些特征，可以增加多个卷积核，不同的卷积核能够得到图像的不同映射下的特征，称之为特征图（Feature Map，也叫特征映射）。如果有100个卷积核，最终的权值参数也仅为100 × 100 = 10^4个而已。另外，偏置参数 b 也是共享的，同一种卷积核（也叫滤波器）共享一个。</p>
<h3 id="卷积与池化：提取高维特征"><a href="#卷积与池化：提取高维特征" class="headerlink" title="卷积与池化：提取高维特征"></a>卷积与池化：提取高维特征</h3><p>我们需要明白，卷积过程与池化过程都降低了我们模型需要训练的权值参数的个数，卷积与池化的目的是在输入数据集上提取高维特征。为了理解卷积过程，请看下图：</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/CNN%E5%B1%80%E9%83%A8%E8%BF%9E%E6%8E%A5%E4%B8%8E%E6%9D%83%E5%80%BC%E5%8F%82%E6%95%B0%E5%85%B1%E4%BA%AB.gif" alt=""></p>
<p>左图整个绿色区域表示一张图片作为输入数据，是一个大小为<code>5*5</code>的矩阵 。而左图的黄色区域表示卷积核（Filter，过滤器），是一个大小为<code>3*3</code>的矩阵。我们看到黄色的卷积核在输入数据上依次移动一个格子，我们称卷积的步长为1 。相应的，如果卷积核依次移动两个格子，则卷积的步长为2 。再次注意观察，输入数据矩阵上一共有9个不同的位置与卷积核一一对应，分别与卷积核进行矩阵相乘运算（即，矩阵对应位置数据相乘所得的全部结果，再进行累加），得到右图所示的矩阵，我们称右图是通过卷积核从左图提取出来的卷积特征（Convolved Feature）矩阵。这个过程就是所谓的卷积过程！</p>
<p>我们设定输入图片为<code>m*m</code>，卷积核为<code>n*n</code>，卷积步长为<code>step</code>，特征矩阵大小为<code>t*t</code>，则它们之间有如下算术关系：</p>
<pre><code>t = [(m - n + 1) / step]    (如有余数，向上取整)
</code></pre><p>另外如果细心观察，你会发现，卷积核在依次移动的过程中，卷积核矩阵中的数字一直没有变化，这就是所谓的权值共享思想。我们可以把卷积核矩阵的每个数据看作是权值参数，我们最终目的就是，在大量训练数据下通过不断用算法调整卷积核矩阵的每个权值参数的数值，使得我们模型的拟合能力达到最优解！</p>
<p>通过不同的卷积核，我们可以提取输入数据集不同的特征矩阵（特征图），所有这些特征图组成特征图集合。那么我们就通过卷积核架起了输入数据与特征图集合之间的桥梁。特征图集合中的每个数据都对应了输入数据集的一个局部区域，这就是上文所解释的局部连接思想的体现。</p>
<p>到此，我们卷积过程的输出就是特征图集合，卷积过程的输出数据作为池化过程的输入数据。上文概述中曾提到“时间或空间下采样”这样一个概念，具体来说，我们的输入是图片数据集，就可以简单的理解为“图片下采样”过程。为了理解池化过程请看下图：</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/CNN%E6%B1%A0%E5%8C%96%E8%BF%87%E7%A8%8B%E6%9C%80%E5%A4%A7%E5%80%BC%E9%87%87%E6%A0%B7%E7%A4%BA%E6%84%8F%E5%9B%BE.png" alt=""></p>
<p>图中显示了池化过程的示意图，池化过程的下采样方式采用最大值取样。以上图为例，左图表示一个特征矩阵，大小为<code>4*4</code>。从左图的特征矩阵中左上角选择一个大小为<code>2*2</code> 的子矩阵，也即，中间的黄色区域表示的矩阵。那么，依次在左图提取一个大小固定为<code>2*2</code> 的子矩阵，并去子矩阵最大值填入右图，得到的矩阵就是我们池化过程得到的结果。池化结果同样作为下一层处理的输入数据集。</p>
<p>我们设定特征矩阵大小为<code>p*p</code>，池化子矩阵大小为<code>q*q</code>，移动步长为<code>pice</code> ，特征矩阵大小为<code>r*r</code>，则它们之间有如下算术关系：</p>
<pre><code>r = [(p - q + 1) / pice]    (如有余数，向上取整)
</code></pre><h3 id="全连接层：对高维特征分类"><a href="#全连接层：对高维特征分类" class="headerlink" title="全连接层：对高维特征分类"></a>全连接层：对高维特征分类</h3><p>一个CNN网络模型，通常由一个或多个卷积层池化层，后面连接一个深度为若干的全连接层构成。上面已经介绍了卷积池化层的作用，以及卷积池化层的具体操作过程的细节，接下来看全连接层。</p>
<p>我们知道，最后一个卷积池化层的输出，将作为全连接层的输入。全连接层的作用是，把卷积池化层提取的高维特征进行分类，正如我们理解的那样，全连接层类似一个普通的多层的深度神经网络，而一个普通深度神经网络的最本质的作用，就是处理分类问题。</p>
<p><img src="http://on1xkrize.bkt.clouddn.com/CNN%E7%BB%8F%E5%85%B8Lenet-5%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt=""></p>
<p>如上图，为了更加深入的理解卷积神经网络，本系列的下一篇文章，我准备以一个经典的卷积神经网络LeNet-5为例，更加详细的讲解卷积神经网络的更多细节。</p>
<h3 id="参考文献：感谢原作者"><a href="#参考文献：感谢原作者" class="headerlink" title="参考文献：感谢原作者"></a>参考文献：感谢原作者</h3><ul>
<li><a href="http://www.36dsj.com/archives/24006" target="_blank" rel="external">技术向：一文读懂卷积神经网络</a></li>
<li><a href="http://www.jeyzhang.com/cnn-learning-notes-1.html" target="_blank" rel="external">卷积神经网络(CNN)学习笔记1：基础入门</a></li>
<li><a href="http://www.moonshile.com/post/juan-ji-shen-jing-wang-luo-quan-mian-jie-xi#toc_18" target="_blank" rel="external">卷积神经网络全面解析</a></li>
<li><a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="external">零基础入门深度学习(4) - 卷积神经网络</a></li>
</ul>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>


    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CNN/" rel="tag"># CNN</a>
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/卷积神经网络/" rel="tag"># 卷积神经网络</a>
          
            <a href="/tags/DeepLearning/" rel="tag"># DeepLearning</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/18/深度学习-深度神经网络概念/" rel="next" title="深度学习笔记：从神经元到深度神经网络（DNN）">
                <i class="fa fa-chevron-left"></i> 深度学习笔记：从神经元到深度神经网络（DNN）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/06/TensorFlow-二维卷积/" rel="prev" title="二维卷积tf.nn.conv2d()各参数解释">
                二维卷积tf.nn.conv2d()各参数解释 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

          
          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="布鲁克林一棵树" />
          <p class="site-author-name" itemprop="name">布鲁克林一棵树</p>
           
              <p class="site-description motion-element" itemprop="description">我是集市里的拾荒者，不看路人，不换爱人！</p>
          
        </div>
        <nav class="site-state motion-element">
        
          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">博客</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">16</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="mailto:wondertwo1@163.com" target="_blank" title="邮箱 wondertwo1@163.com">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  邮箱 wondertwo1@163.com
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/wondertwo" target="_blank" title="布鲁克林一棵树—>GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  布鲁克林一棵树—>GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/u/5182488533" target="_blank" title="布鲁克林一棵树—>微博">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  布鲁克林一棵树—>微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.cnblogs.com/wondertwo/" target="_blank" title="布鲁克林一棵树—>博客园">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  布鲁克林一棵树—>博客园
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.jianshu.com/u/8f34ca2bf35e" target="_blank" title="布鲁克林一棵树—>简书">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  布鲁克林一棵树—>简书
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积神经网络概述"><span class="nav-number">1.</span> <span class="nav-text">卷积神经网络概述</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#局部连接与权值共享"><span class="nav-number">2.</span> <span class="nav-text">局部连接与权值共享</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卷积与池化：提取高维特征"><span class="nav-number">3.</span> <span class="nav-text">卷积与池化：提取高维特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层：对高维特征分类"><span class="nav-number">4.</span> <span class="nav-text">全连接层：对高维特征分类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考文献：感谢原作者"><span class="nav-number">5.</span> <span class="nav-text">参考文献：感谢原作者</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">布鲁克林一棵树</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    
    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  




  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  



  




	





  





  





  



  
  

  

  

  

  


  

</body>
</html>
